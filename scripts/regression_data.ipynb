{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis\n",
    "## Set Up\n",
    "We import ```pandas```, ```numpy```, ```csv```, ```os```, and ```tqdm``` libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import os\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the path to the ```IRS_migration_data``` repository folder in a string variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo_path = os.getcwd()[0:len(os.getcwd())-7]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also create a new ```regression_data``` folder in which we will store the datasets produced by this script, it will be a subfolder of your ```IRS_migration_data``` repository. If such a folder already exists, a new one will not be created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_path = repo_path + 'regression_data/'\n",
    "if not os.path.exists(results_path):\n",
    "    os.makedirs(results_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We upload the data on outflows and inflows from csv files.\n",
    "They cover the period 1998-2015."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outflow_df = pd.read_csv(repo_path + 'outflows/outflow.csv')\n",
    "inflow_df = pd.read_csv(repo_path + 'inflows/inflow.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We print the first 10 lines of the ```inflow_df``` dataframe we just created to see how it is structured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflow_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Population Dataframe\n",
    "As a first step, I create a dataframe with the county fip codes as indexes and the years as columns. I will then fill it with the population for each county and each year extracting it from the IRS data organised in the ```inflow_df``` dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we create an array with all the periods in the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = pd.unique(inflow_df['year'].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create an array with all the fip codes for the counties in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destinations = inflow_df[(inflow_df['state_code_dest']<=56) & ((inflow_df['state_code_origin']<=56))]\n",
    "destination_codes = pd.unique(destinations['destination'].values)\n",
    "destination_codes = set(destination_codes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop the District of Columbia, whose particular status complicates the definition of migration flows into and out from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_codes = destination_codes - {11001}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a smaller dataframe starting from ```inflow_df``` that contains for each county and each year only the two rows necessary to compute the total population:\n",
    "\n",
    "* the number of non-migrants;\n",
    "* the total number of migrants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_data = inflow_df[(inflow_df['destination'].isin(destination_codes))\n",
    "                            & ((inflow_df['origin']==inflow_df['destination']) | (inflow_df['origin']==96000))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two population dataframes, one for households, the other for individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_hh = pd.DataFrame(0, index=destination_codes, columns=years)\n",
    "population_in = pd.DataFrame(0, index=destination_codes, columns=years)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally we fill them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm_notebook(years, desc='year loop'):\n",
    "    for county in tqdm_notebook(destination_codes, desc='county_loop'):\n",
    "        population_hh[year][county] = pop_data[(pop_data['year']==year) & \n",
    "                                               (pop_data['destination']==county)]['return_num'].sum()\n",
    "        population_in[year][county] = pop_data[(pop_data['year']==year) & \n",
    "                                               (pop_data['destination']==county)]['exmpt_num'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given how long it takes to fill them, we save them into a csv file so that we will be able to immediately access them afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_hh.to_csv(results_path + 'population_hh.csv')\n",
    "population_in.to_csv(results_path + 'population_in.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now upload the same dataframe directly from the csv file so that, after we have created the population dataframes the first time, we can skip this part and start from this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_hh = pd.read_csv(results_path + 'population_hh.csv', index_col = 0)\n",
    "population_in = pd.read_csv(results_path + 'population_in.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Migration Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For descriptive purposes, we also construct three other matrices containing respectively:\n",
    "\n",
    "1. the number of migrants moving to a different county wihle remainig in the same state;\n",
    "2. the numebr of migrants crossing a state boundary;\n",
    "3. and the number of migrants moving from/to outside the US.\n",
    "\n",
    "We start by creating a smaller dataframe starting from the ```inflow_df``` containing only the information we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_data = inflow_df[(inflow_df['destination'].isin(set(destination_codes)))\n",
    "                            & ((inflow_df['origin']==97001) | \n",
    "                               (inflow_df['origin']==97003) |\n",
    "                               (inflow_df['origin']==98000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outmigration_data = outflow_df[(outflow_df['origin'].isin(set(destination_codes)))\n",
    "                            & ((outflow_df['destination']==97001) | \n",
    "                               (outflow_df['destination']==97003) |\n",
    "                               (outflow_df['destination']==98000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_ic = pd.DataFrame(0, index=destination_codes, columns=years)\n",
    "immigration_is = pd.DataFrame(0, index=destination_codes, columns=years)\n",
    "immigration_ab = pd.DataFrame(0, index=destination_codes, columns=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outmigration_ic = pd.DataFrame(0, index=destination_codes, columns=years)\n",
    "outmigration_is = pd.DataFrame(0, index=destination_codes, columns=years)\n",
    "outmigration_ab = pd.DataFrame(0, index=destination_codes, columns=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm_notebook(years, desc='year loop'):\n",
    "    for county in tqdm_notebook(destination_codes, desc='county loop'):\n",
    "        immigration_ic[year][county] = immigration_data[(immigration_data['year']==year) & \n",
    "                                                      (immigration_data['destination']==county) &\n",
    "                                                      (immigration_data['origin']==97001)]['exmpt_num'].sum()\n",
    "        \n",
    "        immigration_is[year][county] = immigration_data[(immigration_data['year']==year) & \n",
    "                                                      (immigration_data['destination']==county) &\n",
    "                                                      (immigration_data['origin']==97003)]['exmpt_num'].sum()\n",
    "        \n",
    "        immigration_ab[year][county] = immigration_data[(immigration_data['year']==year) & \n",
    "                                                      (immigration_data['destination']==county) &\n",
    "                                                      (immigration_data['origin']==98000)]['exmpt_num'].sum()\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for year in tqdm_notebook(years, desc='year loop'):\n",
    "    for county in tqdm_notebook(destination_codes, desc='county loop'):\n",
    "        outmigration_ic[year][county] = outmigration_data[(outmigration_data['year']==year) & \n",
    "                                                      (outmigration_data['origin']==county) &\n",
    "                                                      (outmigration_data['destination']==97001)]['exmpt_num'].sum()\n",
    "        \n",
    "        outmigration_is[year][county] = outmigration_data[(outmigration_data['year']==year) & \n",
    "                                                      (outmigration_data['origin']==county) &\n",
    "                                                      (outmigration_data['destination']==97003)]['exmpt_num'].sum()\n",
    "        \n",
    "        outmigration_ab[year][county] = outmigration_data[(outmigration_data['year']==year) & \n",
    "                                                      (outmigration_data['origin']==county) &\n",
    "                                                      (outmigration_data['destination']==98000)]['exmpt_num'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We export the six matrices ```immigration_ic```, ```immigration_is```, ```immigration_ic```, ```outmigration_is```, ```outmigration_ic```, and ```outmigration_ab``` to csv files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "immigration_ic.to_csv(results_path + 'immigration_ic.csv')\n",
    "immigration_is.to_csv(results_path + 'immigration_is.csv')\n",
    "immigration_ab.to_csv(results_path + 'immigration_ab.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outmigration_ic.to_csv(results_path + 'outmigration_ic.csv')\n",
    "outmigration_is.to_csv(results_path + 'outmigration_is.csv')\n",
    "outmigration_ab.to_csv(results_path + 'outmigration_ab.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Dataset\n",
    "We now set up the final dataset which will contain year, destination code, origin code, household flow, population in the destination, and population at the origin. The two population columns will be added in a second step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data = inflow_df[(inflow_df['destination'].isin(set(destination_codes))) &\n",
    "                     (inflow_df['origin'].isin(set(destination_codes))) &\n",
    "                     (inflow_df['destination']!=inflow_df['origin'])]\n",
    "reg_data = reg_data[['year', 'destination', 'origin', 'return_num', 'exmpt_num']]\n",
    "reg_data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the ```pop_cols_hh``` dataframe. It restructures the data in the ```population_hh``` dataframe so that it can be merged with the ```reg_data``` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_cols_hh = pd.DataFrame(index=range(0,len(destination_codes)*years.size), columns=['year','county','pop_hh'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we fill it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for county in destination_codes:\n",
    "    for year in years:\n",
    "        pop_cols_hh['year'][i] = year\n",
    "        pop_cols_hh['county'][i] = county\n",
    "        pop_cols_hh['pop_hh'][i] = population_hh.loc[county][year]\n",
    "    \n",
    "        i = i+1\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the operation with the ```population_in``` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_cols_in = pd.DataFrame(index=range(0,len(destination_codes)*years.size), columns=['year','county','pop_in'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for county in destination_codes:\n",
    "    for year in years:\n",
    "        pop_cols_in['year'][i] = year\n",
    "        pop_cols_in['county'][i] = county\n",
    "        pop_cols_in['pop_in'][i] = population_in.loc[county][year]\n",
    "    \n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now merge the two dataframes to create first the column with the population at the destination and then the one with the population at the origin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_data.rename(columns={'destination':'county'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(reg_data, pop_cols_hh, how='left', on=['year', 'county'])\n",
    "result = pd.merge(result, pop_cols_in, how='left', on=['year', 'county'])\n",
    "result.rename(columns={'county':'destination', 'origin':'county', \n",
    "                       'pop_hh':'pop_destination_hh', 'pop_in':'pop_destination_in'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.merge(result, pop_cols_hh, how='left', on=['year', 'county'])\n",
    "result = pd.merge(result, pop_cols_in, how='left', on=['year', 'county'])\n",
    "result.rename(columns={'county':'origin',\n",
    "                       'pop_hh':'pop_origin_hh', 'pop_in':'pop_origin_in'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last step is to add a group variable and a treatment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_sandy_counties = pd.read_csv(repo_path + 'county_groups/disaster_sandy_counties.csv', usecols = ['fip_code'])\n",
    "nearby_sandy_counties = pd.read_csv(repo_path + 'county_groups/nearby_sandy_counties.csv', usecols = ['fip_code'])\n",
    "distant_sandy_counties = pd.read_csv(repo_path + 'county_groups/distant_sandy_counties.csv', usecols = ['fip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_kat_counties = pd.read_csv(repo_path + 'county_groups/disaster_kat_counties.csv', usecols = ['fip_code'])\n",
    "nearby_kat_counties = pd.read_csv(repo_path + 'county_groups/nearby_kat_counties.csv', usecols = ['fip_code'])\n",
    "distant_kat_counties = pd.read_csv(repo_path + 'county_groups/distant_kat_counties.csv', usecols = ['fip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nc_urban_counties = pd.read_csv(repo_path + 'county_groups/urban_nc_counties.csv', usecols = ['fip_code'])\n",
    "coastal_counties = pd.read_csv(repo_path + 'county_groups/coastline_counties.csv', usecols = ['fip_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "county_groups = [disaster_sandy_counties, nearby_sandy_counties, distant_sandy_counties,\n",
    "                 disaster_kat_counties, nearby_kat_counties, distant_kat_counties]\n",
    "groups = ['disaster', 'nearby', 'distant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group = 0\n",
    "\n",
    "for df in county_groups:\n",
    "    \n",
    "    if group<=2:\n",
    "        df['group'] = groups[group]\n",
    "    else:\n",
    "        group = 0\n",
    "        df['group'] = groups[group]\n",
    "        \n",
    "    group = group +1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sandy_group = county_groups[0].append(county_groups[1])\n",
    "sandy_group = sandy_group.append(county_groups[2])\n",
    "\n",
    "katrina_group = county_groups[3].append(county_groups[4])\n",
    "katrina_group = katrina_group.append(county_groups[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nc_urban_counties['urban'] = 'urban'\n",
    "coastal_counties['coastal'] = 'coastal'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={'destination':'fip_code'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, sandy_group, how='left', on=['fip_code'])\n",
    "result.rename(columns={'group':'sandy_group_dest'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, katrina_group, how='left', on=['fip_code'])\n",
    "result.rename(columns={'group':'kat_group_dest'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, all_nc_urban_counties, how='left', on=['fip_code'])\n",
    "result.rename(columns={'urban':'urban_dest'}, inplace=True)\n",
    "result['urban_dest'] = result['urban_dest'].where(result['urban_dest']=='urban', 'rural')\n",
    "\n",
    "result = pd.merge(result, coastal_counties, how='left', on=['fip_code'])\n",
    "result.rename(columns={'coastal':'coastal_dest'}, inplace=True)\n",
    "result['coastal_dest'] = result['coastal_dest'].where(result['coastal_dest']=='coastal', 'continental')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.rename(columns={'fip_code':'destination'}, inplace=True)\n",
    "result.rename(columns={'origin':'fip_code'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, sandy_group, how='left', on=['fip_code'])\n",
    "result.rename(columns={'group':'sandy_group_origin'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, katrina_group, how='left', on=['fip_code'])\n",
    "result.rename(columns={'group':'kat_group_origin'}, inplace=True)\n",
    "\n",
    "result = pd.merge(result, all_nc_urban_counties, how='left', on=['fip_code'])\n",
    "result.rename(columns={'urban':'urban_origin'}, inplace=True)\n",
    "result['urban_origin'] = result['urban_origin'].where(result['urban_origin']=='urban', 'rural')\n",
    "\n",
    "result = pd.merge(result, coastal_counties, how='left', on=['fip_code'])\n",
    "result.rename(columns={'coastal':'coastal_origin'}, inplace=True)\n",
    "result['coastal_origin'] = result['coastal_origin'].where(result['coastal_origin']=='coastal', 'continental')\n",
    "\n",
    "result.rename(columns={'fip_code':'origin'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We store the results in a dataframe called ```gravity_data``` which can then be used to estimate the gravity model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_data = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we export the ```gravity_data``` dataframe to a csv file on which we will perform the regression analysis using Stata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gravity_data.to_csv(results_path + 'gravity_data.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
